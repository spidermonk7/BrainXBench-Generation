import requests
import json

# æŸ¥è¯¢ Internet Archiveï¼Œè·å–å¼€æ”¾ä¹¦ç±çš„å¯ç”¨æ ¼å¼
def fetch_book_text(query, max_results=5):
    search_url = "https://archive.org/advancedsearch.php"
    params = {
        'q': query,
        'fl[]': 'identifier,title,creator,year,language',
        'sort': 'year desc',
        'rows': max_results,
        'output': 'json'
    }
    
    response = requests.get(search_url, params=params)
    response.raise_for_status()
    data = response.json()

    books = []
    for doc in data['response']['docs']:
        book_id = doc['identifier']
        book = {
            'Title': doc.get('title', 'N/A'),
            'Author': doc.get('creator', 'N/A'),
            'Year': doc.get('year', 'N/A'),
            'Language': doc.get('language', 'N/A'),
            'TXT URL': f"https://archive.org/download/{book_id}/{book_id}.txt",  # çº¯æ–‡æœ¬ç‰ˆæœ¬
            'XML URL': f"https://archive.org/download/{book_id}/{book_id}_djvu.xml",  # OCR XML ç‰ˆæœ¬
            'PDF URL': f"https://archive.org/download/{book_id}/{book_id}.pdf"  # PDF ç‰ˆæœ¬
        }
        books.append(book)

    return books

import requests

# ç»Ÿä¸€çš„ä¸‹è½½å‡½æ•°ï¼ˆé€‚ç”¨äº TXT/XMLï¼‰
def download_book_text(url, filename, file_type="text"):
    """
    é€šç”¨çš„æ–‡æœ¬æ–‡ä»¶ä¸‹è½½å™¨ï¼Œé€‚ç”¨äº TXT å’Œ XMLã€‚
    """
    try:
        response = requests.get(url, stream=True, timeout=10)
        if response.status_code == 200:
            with open(filename, 'w', encoding='utf-8') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:  # é¿å…å†™å…¥ç©ºå—
                        f.write(chunk.decode('utf-8', errors='ignore'))  # å¤„ç†å¯èƒ½çš„è§£ç é”™è¯¯
            print(f"âœ… {file_type.upper()} ä¹¦ç±ä¸‹è½½å®Œæˆ: {filename}")
        else:
            print(f"âŒ ä¹¦ç±ä¸‹è½½å¤±è´¥ï¼ˆ{file_type.upper()}ï¼‰ï¼ŒHTTP çŠ¶æ€ç : {response.status_code}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ï¼ˆ{file_type.upper()}ï¼‰: {e}")


# PDF ä¸‹è½½å‡½æ•°ï¼ˆé€‚ç”¨äºäºŒè¿›åˆ¶æ–‡ä»¶ï¼‰
def download_book_pdf(url, filename):
    """
    ä¸‹è½½ PDF æ–‡ä»¶ã€‚
    """
    try:
        response = requests.get(url, stream=True, timeout=15)
        if response.status_code == 200:
            with open(filename, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:  # é¿å…å†™å…¥ç©ºå—
                        f.write(chunk)
            print(f"âœ… PDF ä¹¦ç±ä¸‹è½½å®Œæˆ: {filename}")
        else:
            print(f"âŒ ä¹¦ç±ä¸‹è½½å¤±è´¥ï¼ˆPDFï¼‰ï¼ŒHTTP çŠ¶æ€ç : {response.status_code}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ PDF ä¸‹è½½å¤±è´¥: {e}")


if __name__ == "__main__":
    # è·å–ç¥ç»ç§‘å­¦ç›¸å…³çš„ä¹¦ç± TXT ç‰ˆæœ¬
    books = fetch_book_text("neuroscience", max_results=5)
    for idx, book in enumerate(books, 1):
        print(f"Book {idx}:")
        print(f"Title: {book['Title']}")
        print(f"Author: {book['Author']}")
        print(f"Year: {book['Year']}")
        print(f"Language: {book['Language']}")
        print(f"TXT URL: {book['TXT URL']}")
        print(f"XML URL: {book['XML URL']}")
        print(f"ğŸ¤–: Downloading from link: {book['PDF URL']}")
        # download_book_text(book['TXT URL'], f"{book['Title']}.txt")
        download_book_pdf(book['PDF URL'], f"{book['Title']}.pdf")
        print('-' * 80)
