===== Page 1 =====
1412    Part VIII / Learning, Memory, Language and Cognition
information processing, nor does it explain the neu-
ral mechanisms that support these computations. It 
mainly tells us about the level of brain organization that 
carries out these operations. For example, consider the 
search for the neurons that achieve knowledge about 
the color red, despite changes in the spectral content 
of the morning and evening light—a phenomenon 
known as color constancy. Instead of searching in sen-
sory areas for neurons that respond selectively to red 
in this invariant way, one might look for neurons that 
guide the choice of ripe fruit. This does not obviate the 
computations required to recover the surface reflec-
tance properties of the fruit’s skin, despite variation in 
the spectral content of the illuminating light. The raw 
data for such computations are supplied by sensory 
neurons that lack color constancy and maintain tem-
poral fidelity with changes in the environment. The 
knowledge state “red,” however, is invariant to the 
illuminant and likely persistent. In animals that lack 
language, the knowledge state may not be dissociable 
from “ripe vegetation.”
The second caveat is that we have not distin-
guished knowledge states that we are consciously 
aware of from those that we experience unconsciously. 
For example, as I make my way through the forest 
trying to find the creek that I hear burbling, my brain 
might consider locations of objects I pass that are 
graspable, attached to vegetation, and with color sug-
gesting ripeness. I may be unaware of this consciously. 
Yet that evening in my search for food, I may return 
to this part of the forest, guided by these unconscious 
encounters. I may do this without knowing why, or the 
memory might pierce consciousness. All that has been 
said up to now could apply to conscious and noncon-
scious experience. We are now prepared to elucidate 
the difference.
Consciousness Can be Understood Through the 
Lens of Decision Making
Clearly, we are unaware of most of the operations 
that transpire in our brains, and this is true even for 
the processes that ultimately pierce consciousness. 
This is why Freud famously quipped that conscious-
ness is overrated. Every thought that enters our 
awareness began as neural computation preceding 
the conscious awareness of that thought. Indeed, 
the sophistication of nonconscious mental processes, 
including those leading to “I’ve got it!” moments and 
the activities we perform while occupied by a phone 
call, involves decisions that transpire without con-
scious awareness.
It is difficult to study nonconscious processing 
because people deny experience of the process. Indeed, 
the term nonconscious experience seems like an oxy-
moron. The experimenter must find a way to prove 
that information processing has occurred despite the 
fact that the subject is unaware of it. In recent years, it 
has become possible to establish conditions whereby 
information is provided to a human subject that has a 
high likelihood of going unnoticed but is nonetheless 
able to influence behavior, thereby permitting scien-
tific characterization of nonconscious mental process-
ing (Chapter 59). This has encouraged neuroscientists 
to ask what it is about the neural activity that gives 
rise to the thoughts, perceptions, and movements that 
do reach conscious awareness. We will not review this 
vast topic here but instead share a pertinent insight: 
Viewed through the lens of decision-making, the prob-
lem of consciousness may be simpler than imagined.
Broadly speaking, two sets of phenomena fall under 
the heading consciousness. The first concerns levels of 
arousal. One is not conscious when one is asleep, under 
general anesthesia, comatose, or having a generalized 
seizure. One is fully conscious when awake, and there 
are levels of consciousness between these extremes. 
These states are associated with terms such as confu-
sion, dissociation, stupor, and obtundation. Some alter-
ations of consciousness are normal (eg, sleep), whereas 
others are induced by toxins (eg, alcohol), metabolic dis-
turbances (eg, hypoglycemia), low oxygen, trauma (eg, 
concussion), or fever (eg, delirium).
The neuroscience underlying these states—and the 
transitions between them—is immensely important to 
medicine. We might classify this group of phenomena 
as neurology-consciousness. However, these topics are 
not what most people mean when they speak of the 
mystery of consciousness. This is partly because they 
are less mysterious but also because their characteriza-
tion is more objective and the phenomena can be stud-
ied in animals. That said, there is much to be learned 
about the mechanisms responsible for sleep, awaken-
ing, anesthesia, and so forth. Much of the neuroscience 
is unfolding at a rapid pace (Chapter 44).
We will not say more about neurology-consciousness 
here, except to seed one useful insight. Imagine a 
mother and father sleeping comfortably in their bed-
room as a storm ensues outdoors. There are also traf-
fic sounds and even the occasional thunder. This scene 
goes on for some time, until the cry of a baby awakens 
the parents. This common occurrence tells us that the 
nonconscious brain is capable of processing sounds 
and deciding to become conscious. It decides, noncon-
sciously, that some sounds afford an opportunity for 
more sleep while others sound a call to nurture. This 


===== Page 2 =====
Chapter 56 / Decision-Making and Consciousness    1413
decision is similar to the perceptual decisions consid-
ered earlier in this chapter. Both involve nonconscious 
processing of evidence. However, the commitment to 
awaken and parent is a decision to engage the environ-
ment consciously. This may be a touchstone between 
neurology-consciousness and the more intriguing con-
sciousness that you are experiencing as you read these 
words (or so the authors hope).
When neuroscientists, psychologists, and philoso-
phers ponder the mysteries of consciousness, they are 
referring to loftier themes than wakefulness. This loftier 
set of phenomena comprises awareness, imagery, voli-
tion, and agency. There is a subjective component to all 
conscious experience. The experience of conscious per-
ception incorporates a sense that it is me that is behold-
ing the content. It parallels the “me” in volition. It 
is not that my arm moved on its own; I made it move! 
We used the term deliberation earlier in this chapter to 
describe the thought process leading to a decision. Our 
use of the term was metaphorical. It describes a com-
putation and a biological mechanism, but it does not 
require awareness. Actual deliberation implies con-
scious intention. We are aware of the steps of reasoning 
along the way. We could report, were we asked, about 
the evidence we relied upon—that is, the evidence we 
were consciously aware of during the decision and pos-
sibly some of the evidence we used nonconsciously 
were it accessible from memory to include in our report. 
Could the difference between conscious awareness of 
an item and nonconscious processing of that item be 
a mere matter of whether the brain has decided on the 
possibility of reporting? Could it be this simple?
Consider the following scenario. A psychologist 
concludes that a study participant has seen something 
nonconsciously because the item affected a subsequent 
behavior and the participant denies having seen it. Sup-
pose the subsequent behavior involved reaching in the 
direction of the object. Based on what we know about 
decision-making, we would conclude that brain circuits 
like the ones discussed earlier received sufficient evi-
dence to commit to the possibility of looking, reaching, 
and approaching, but there was insufficient evidence to 
commit to the possibility of reporting. Just as the brain 
entertains the possibility of looking, reaching, or grasp-
ing, it may also entertain the possibility of reporting. 
That is, reporting is also a provisional affordance.
Events afford the possibility of reporting, and 
this includes the nonconscious states of knowledge 
acquired through decision-making. Indeed, the event 
of having decided may be experienced consciously—
the aha moment—by virtue of another decision to 
report. In the study scenario, the participant was not 
consciously aware of the item because her brain did 
not commit to a provisional report. The evidence did 
not satisfy a decision criterion like the termination 
bounds in the perceptual decision-making task consid-
ered earlier in the chapter.
This account provides a plausible explanation of 
the failure of the participant to report that she saw the 
item, but the mere entertaining of the possibility of 
reporting does not seem to explain the phenomenol-
ogy of the perceptual experience itself, at least not at 
first glance. This explanation demands more careful 
consideration of the character of the report. Just as we 
attach states of spatial knowledge to configurations of 
the hand for reaching and grasping, we must consider 
the knowledge state that accompanies the affordance 
of reporting. Whether by language or gesture (eg, 
pointing), the report is a provisional communication 
with another agent or oneself (eg, in the future). It pre-
sumes knowledge about the mind of the receiver.
Cognitive scientists use the term theory of mind to 
refer to this type of knowledge or mental capacity. It can 
be demonstrated by asking someone to reason about 
the motivation behind another agent’s actions, and it 
can be studied in animals and preverbal children by 
examining their reactions to another child or puppet. 
In one study protocol, two children witness a desired 
toy placed in a left or right container (Figure 62–2). The 
test child then witnesses the toy’s displacement to the 
other container while the other child is absent. When 
that child returns, the experimenter assesses the test 
child’s expectation of which container the returning 
child will open to find the toy. Children under 3 years 
old do not exhibit theory of mind by this assay. They 
think the returning child will open the container that 
contains the toy, not the one it was in before the transfer.  
Whether animals other than humans have theory of 
mind is controversial. We suspect there are incho-
ate forms of this capacity in the animal kingdom and 
in children under 3. When adults perform tasks that 
depend on theory of mind, the right temporal-parietal 
junction and superior temporal sulcus are active.
Theory of mind—in concert with narrative—has 
profound consequences for the knowledge state asso-
ciated with the reporting affordance. Imagine a woman 
looking at a power drill resting on a table. She experi-
ences the location of the drill, relative to her eyes and 
hand, as well as its texture and shape. It has a grasp-
able surface that is partly in her line of sight and partly 
occluded (eg, the back). These are the knowledge 
states that arise through provisional commitments to 
look at, reach for, and grasp the drill. They are likely 
to involve neural activity similar to what is illustrated 
in Figure 56–7, and they are the outcome of simple 
decisions. The drill brings to mind other affordances 


===== Page 3 =====
1414    Part VIII / Learning, Memory, Language and Cognition
associated with its utility as a tool, its potential to make 
noise, and the potential danger posed by the sharp bit 
at one end. This is an elaborate, potentially rich col-
lection of knowledge, but it could all be experienced 
nonconsciously. For example, if the woman were pre-
occupied with some other task, such as a phone con-
versation with her friend, she might nonetheless make 
use of these knowledge states.
But suppose there is a man on the other side of the 
table and suppose the woman—her brain, that is—has 
also reached a provisional commitment to report to the 
man about the drill between them. Consider the change 
to her knowledge state. The drill now has a presence 
not only in her visual field, relative to her gaze, her 
hand, and her repertory of actions, but also in the man’s 
field of vision and his possible actions. The parts of the 
drill that are not in plain sight to her are known to be 
in the line of sight of the man. Indeed, her capacity for 
“theory of mind” also supplies knowledge that other 
parts of the drill are seen only by her and that the man 
could be experiencing those parts just as she experi-
ences the parts that are not in her direct line of sight—
that is, both preconsciously as occluded parts of the 
object and consciously as part of an object that could 
be seen directly from another vantage point. There is 
something about the drill that is at once private, pub-
lic, and in the world—independent of either mind. The 
drill is there for the next person who enters the room, or 
an imagined person. The transformation of knowledge 
of the drill is from a collection of first-person experi-
ences (eg, qualities and affordances) to a thing in the 
world that possesses an existence unto itself. It is con-
ceivable that this state of knowledge is our conscious 
awareness of the world, or at least a part of it, for the 
knowledge state associated with a decision to report is 
further enriched by content of the report itself.
The report might be simple, like pointing to the 
location of a tool or a hiding spot, or it might involve 
narrative. In the case of the hiding spot, additional con-
tent might be conveyed to indicate that the enclosure 
affords safety from a predator or, alternatively, a pred-
ator’s location. Many simple reports do not require 
narrative because items such as tools and enclosures 
persist and theory of mind presumes the affordance 
of a tool or a hiding place in another’s mind, whereas 
events, which also afford the possibility of reporting, 
often require narrative because they are transient.
The knowledge state associated with narrative can 
incorporate history, simulation, prediction, etiology 
(eg, origin stories), purpose, and consequence. For the 
drill, narrative might enhance the knowledge state to 
include memory of the place of purchase, an episode 
in which it malfunctioned, and the mechanism of its 
detachable bit. Narrative allows us to reason in more 
complex environments than the scenarios considered 
earlier (eg, the umbrella example and the probabilistic 
reasoning task; Figure 56–9). We could not reason about 
science, medical diagnosis, and jurisprudence without 
origin stories, simulation, hypotheses, prospection, 
and counterfactuals. The evolutionary advantage of 
this capacity is obvious (at least for the time being, 
until it leads us to make the earth uninhabitable).
To summarize, the conscious awareness of an item 
might arise when the nonconscious brain reaches a 
decision to report the item to another mind. The inten-
tion is provisional in that no overt report—verbal or 
gesture—need occur, just as no eye movement need 
ensue for the parietal cortex to engage the possible 
intention of foveating. Just as the provisional intention 
to foveate corresponds to preconscious knowledge 
of the location of an as yet unidentified object in the 
periphery, the possibility of reporting to another agent 
(or self), about whom we have theory of mind, corre-
sponds to the knowledge of an item in a way that satis-
fies most aspects of conscious awareness.
Naturally, our journey from perceptual decision-
making through affordances to consciousness is at 
best incomplete. For example, it does not yet provide 
a satisfying account of what a conscious experience 
feels like. But it is a start, as it supplies a coarse expla-
nation of why sensory information acquired through 
the eyes is experienced differently from auditory or 
somatosensory experiences, and it provides insight 
into the private aspects of perceptual awareness 
as well as our experience of objects as things in the 
world, independent of what they afford to the per-
ceiver. These last features follow from the considera-
tion of another agent’s mind.
The view of consciousness from the perspective of 
decision-making is, if nothing else, simplifying. There 
is no reason to search for a special area of the brain 
that bestows consciousness, or a special neuron type, 
or a special ingredient in the representation of infor-
mation (eg, an oscillation or synchronization), or a spe-
cial mechanism. The mechanism might look like any 
other kind of provisional commitment—that is, a deci-
sion that confers a state of knowing but does not entail 
conscious awareness. Of course, brain activity itself is 
not conscious, just as the brain activity supporting a 
possible hand posture is not the hand posture itself. 
In this sense, the mechanism of consciousness is only 
different from other affordances because it involves 
reporting instead of reaching, looking toward, eating, 
drinking, hiding from, walking through, and mating. 
All are likely to involve decision formation and thresh-
old detection.


===== Page 4 =====
Chapter 56 / Decision-Making and Consciousness    1415
Thus, by studying the neuroscience of decision-
making, we are also studying the neuroscience of 
consciousness. There is still much to be learned about 
the mechanisms of the simplest decisions described in 
the first part of the chapter. For example, we do not 
know what sets the bounds and how thresholds are 
implemented in brain circuits. Nevertheless, answers 
to these and other fundamental questions are in the 
crosshairs of modern neuroscience, and therefore, so is 
human consciousness.
Highlights
  1.  A decision is a commitment to a proposition, 
action, or plan—among options—based on evi-
dence, prior knowledge, and expected outcomes. 
The commitment does not necessitate immediate 
action or any behavior, and it may be modified.
  2.  Decision-making provides a window on the 
neuroscience of cognition. It models contingent 
behavior and mental operations that are free 
from the immediate demands of sensory process-
ing and control of the body’s musculature.
  3.  A decision is formed by applying a rule to the 
state of evidence bearing on the alternatives. A 
simple decision rule for choosing between two 
alternatives employs a criterion. If the evidence 
exceeds the criterion, then choose the alterna-
tive supported by the evidence; if not, choose the 
other alternative.
  4.  For certain perceptual decisions, the source of evi-
dence and its neural representation are known.
  5.  The accuracy of many decisions is limited by 
considerations of the signal strength and its 
associated noise. For neural systems, this noise 
is attributed to the variable discharge of sin-
gle neurons, hence the variable firing rate of 
small populations of neurons that represent the 
evidence.
  6.  Many decisions benefit from multiple samples of 
evidence, which are combined across time. Such 
decision processes take time and require neural 
representations that can hold and update the 
accumulated evidence (ie, the decision variable). 
Neurons in the prefrontal and parietal cortex, 
which are capable of holding and updating their 
firing rates, represent the evolving decision vari-
able. These neurons are also involved in plan-
ning, attention, and working memory.
  7.  The speed–accuracy trade-off is controlled by 
setting a bound or threshold on the amount of 
evidence required to terminate a decision. It is 
an example of a policy that makes one decision-
maker different from another.
  8.  Many decisions are about propositions, items, or 
goals that differ in value to the organism. Such 
value-based decisions depend on stored associa-
tions between items and valence.
  9.  The source of evidence for many decisions is mem-
ory and active interrogation of the environment—
information seeking. These operations come into 
play when animals forage and explore, and when 
a jazz musician improvises.
10.  Decision-making invites us to consider knowl-
edge not as an emergent property of neural rep-
resentations but the result of directed, mostly 
nonconscious interrogation of evidence bearing 
on propositions, plans, and affordances. The 
intention is provisional in that no overt action 
need ensue. Just as the provisional intention to 
foveate corresponds to preconscious knowledge 
of the location of an as yet unidentified object 
in the periphery, the possibility of reporting to 
another agent (or self), about whom we have the-
ory of mind, corresponds to the knowledge of an 
item in the ways we are aware of it consciously.
11.  Viewed through the lens of decision-making, con-
scious awareness of an item might arise when the 
nonconscious brain reaches a decision to report to 
another mind. The affordance has the quality of 
narrative, much like silent speech or the idea pre-
ceding its expression in language. It also imbues 
objects with a presence in the environment inhab-
ited by other minds, hence independent of the 
mind of the perceiver. It confers private and public 
content to aspects of the object as perceived.
 Michael N. Shadlen 
 Eric R. Kandel 
Selected Reading
Clark A. 1997. Being There: Putting brain, body, and world 
together again. Cambridge, MA: MIT Press. 269 pp.
Dehaene S. 2014. Consciousness and the Brain: Deciphering How 
the Brain Codes Our Thoughts. New York: Viking.
Dennett D. 1991. Consciousness Explained. Boston: Little, 
Brown.
Donlea JM, Pimentel D, Talbot CB, et al. 2018. Recurrent circuitry 
for balancing sleep need and sleep. Neuron 97:378–389.e4.


===== Page 5 =====
1416    Part VIII / Learning, Memory, Language and Cognition
Gibson JJ. 2015. The Ecological Approach to Visual Perception. 
Classic Edition. New York: Psychology Press.
Graziano MSA, Kastner S. 2011. Human consciousness and 
its relationship to social neuroscience: a novel hypothesis. 
Cogn Neurosci 2:98–113.
Green DM, Swets JA. 1966. Signal Detection Theory and 
Psychophysics. New York: John Wiley and Sons, Inc.
Kang YHR, Petzschner FH, Wolpert DM, Shadlen MN. 2017. 
Piercing of consciousness as a threshold-crossing opera-
tion. Curr Biol 27:2285–2295.
Laming DRJ. 1968. Information Theory of Choice-Reaction Times. 
New York: Academic Press.
Link SW. 1992. The Wave Theory of Difference and Similarity. 
Hillsdale, NJ: Lawrence Erlbaum Associates.
Luce RD. 1986. Response Times: Their Role in Inferring Elementary 
Mental Organization. New York: Oxford University Press.
Markkula G. 2015. Answering questions about conscious-
ness by modeling perception as covert behavior. Front 
Psychol 6:803.
Merleau-Ponty M. 1962. Phenomenology of Perception. London: 
Routledge & Kegan Paul Ltd.
Rangel A, Camerer C, Montague PR. 2008. A framework for 
studying the neurobiology of value-based decision-making. 
Nat Rev Neurosci 9:545–556.
Saxe R, Baron-Cohen S. 2006. The neuroscience of theory of 
mind. Soc Neurosci 1:i–ix.
Shadlen MN, Newsome WT. 1994. Noise, neural codes and 
cortical organization. Curr Opin Neurobiol 4:569–579.
Vickers D. 1979. Decision Processes in Visual Perception. London: 
Academic Press.
Wimmer H, Perner J. 1983. Beliefs about beliefs: representation 
and constraining function of wrong beliefs in young chil-
dren’s understanding of deception. Cognition 13:103–128.
References
Albright TD, Desimone R, Gross CG. 1984. Columnar organi-
zation of directionally selective cells in visual area MT of 
macaques. J Neurophysiol 51:16–31.
Andersen RA, Gnadt JW. 1989. Posterior parietal cortex. Rev 
Oculomot Res 3:315–335.
Born RT, Bradley DC. 2005. Structure and function of visual 
area MT. Annu Rev Neurosci 28:157–189.
Brincat SL, Siegel M, von Nicolai C, Miller EK. 2018. Gradual 
progression from sensory to task-related processing in 
cerebral cortex. Proc Natl Acad Sci U S A 115:E7202-E7211.
Britten KH, Shadlen MN, Newsome WT, Movshon JA. 1992. 
The analysis of visual motion: a comparison of neuronal 
and psychophysical performance. J. Neurosci. 12: 4745–65.
Brody CD, Hernandez A, Zainos A, Romo R. 2003. Tim-
ing and neural encoding of somatosensory parametric 
working memory in macaque prefrontal cortex. Cereb 
Cortex 13:1196–1207.
Constantinidis C, Funahashi S, Lee D, et al. 2018. Persistent 
Spiking Activity Underlies Working Memory. J Neurosci 
38:7020–7028.
Ditterich J, Mazurek M, Shadlen MN. 2003. Microstimulation 
of visual cortex affects the speed of perceptual decisions. 
Nat Neurosci 6:891–898.
Fetsch CR, Odean NN, Jeurissen D, El-Shamayleh Y, Horwitz 
GD, Shadlen MN. 2018. Focal optogenetic suppression in 
macaque area MT biases direction discrimination and 
decision confidence, but only transiently. Elife 7:e36523.
Funahashi S, Bruce C, Goldman-Rakic P. 1989. Mnemonic 
coding of visual space in the monkey’s dorsolateral pre-
frontal cortex. J Neurophysiol 61:331–349.
Gnadt JW, Andersen RA. 1988. Memory related motor plan-
ning activity in posterior parietal cortex of monkey. Exp 
Brain Res 70:216–220.
Gold JI, Shadlen MN. 2007. The neural basis of decision mak-
ing. Annu Rev Neurosci 30:535–574.
Kiani R, Hanks TD, Shadlen MN. 2008. Bounded integration 
in parietal cortex underlies decisions even when view-
ing duration is dictated by the environment. J Neurosci 
28:3017–3029.
Kiani R, Shadlen MN. 2009. Representation of confidence 
associated with a decision by neurons in the parietal cor-
tex. Science 324:759–764.
Mazurek ME, Roitman JD, Ditterich J, Shadlen MN. 2003. A 
role for neural integrators in perceptual decision making. 
Cereb Cortex 13:1257–1269.
Mountcastle VB, Steinmetz MA, Romo R. 1990. Frequency 
discrimination in the sense of flutter: psychophysi-
cal measurements correlated with postcentral events in 
behaving monkeys. J Neurosci 10:3032–3044.
Padoa-Schioppa C. 2011. Neurobiology of economic choice: a 
good-based model. Ann Rev Neurosci 34:333–359.
Padoa-Schioppa C, Assad JA. 2006. Neurons in the orbito-
frontal cortex encode economic value. Nature 441:223–226.
Roitman JD, Shadlen MN. 2002. Response of neurons in the 
lateral intraparietal area during a combined visual dis-
crimination reaction time task. J Neurosci 22:9475–9489.
Romo R, Salinas E. 2001. Touch and go: decision-making 
mechanisms in somatosensation. Annu Rev Neurosci 
24:107–137.
Salzman CD, Britten KH, Newsome WT. 1990. Cortical 
microstimulation influences perceptual judgements of 
motion direction. Nature 346:174–177.
Snyder LH, Batista AP, Andersen RA. 1997. Coding of inten-
tion in the posterior parietal cortex. Nature 386:167–170.
Yang T, Shadlen MN. 2007. Probabilistic reasoning by neu-
rons. Nature 447:1075–1080.


===== Page 6 =====
Part IX


===== Page 7 =====
Preceding Page
Bedroom at Arles by Vincent Van Gogh. Van Gogh wrote to his friend and fellow painter, 
Gaugin, that he had felt “my vision was strangely tired. Well, I rested for two and a 
half days, and then I got back to work. But not yet daring to go outside, I did . . . a no. 
30 canvas of my bedroom with the whitewood furniture that you know. Ah, well, it 
amused me enormously doing this bare interior. With a simplicity à la Seurat. In flat 
tints, but coarsely brushed in full impasto, the walls pale lilac, the floor in a broken and 
faded red, the chairs and the bed chrome yellow, the pillows and the sheet very pale 
lemon green, the blanket blood-red, the dressing-table orange, the washbasin blue, the 
window green. I had wished to express utter repose with all these very different tones, 
you see, among which the only white is the little note given by the mirror with a black 
frame (to cram in the fourth pair of complementaries as well).” Van Gogh had psychotic 
episodes, but there is still debate about the cause—among the theories considered 
have been bipolar disorder, temporal lobe epilepsy, syphilis, schizophrenia, and even 
toxicity from the foxglove plant (a remedy for mental illness at the time) in combination 
with lead poisoning from his oil paints and the consumption of absinthe. (Van Gogh 
Museum, Amsterdam.)


===== Page 8 =====
IX
Diseases of the Nervous System 
He remembered that during his epileptic fits, or rather immedi-
ately preceding them, he had always experienced a moment or two 
when his whole heart, and mind, and body seemed to wake up to 
vigour and light; when he became filled with joy and hope, and 
all his anxieties seemed to be swept away forever; these moments 
were but presentiments, as it were of the one final second (it was 
never more than a second) in which the fit came upon him. That 
second, of course, was inexpressible. When his attack was over, and 
the prince reflected on his symptoms, he used to say to himself: 
“These moments, short as they are, when I feel such extreme con-
sciousness of myself, and consequently more of life than at other 
times, are due only to the disease—to the sudden rupture of normal 
conditions. Therefore they are not really a higher kind of life, but a 
lower.” This reasoning, however, seemed to end in a paradox, and 
lead to the further consideration: —“What matter though it be only 
disease, an abnormal tension of the brain, if when I recall and ana-
lyze the moment, it seems to have been one of harmony and beauty 
in the highest degree—an instant of deepest sensation, overflowing 
with unbounded joy and rapture, ecstatic devotion, and completest 
life?” Vague though this sounds, it was perfectly comprehensible to 
Muishkin, though he knew that it was but a feeble expression of his 
sensations.*
W
hat, exactly, is the nature of the relationship between 
the mind and the brain? Dostoevsky’s own experience of 
epilepsy profoundly influenced his writing, and in this pas-
sage, he probes some of the most profound questions about human 
experience. Are our thoughts and moods simply transient combina-
tions of chemicals and electrical signals? Do we have any influence 
over them? If not, can we be held responsible for our actions? What if 
some of our peak experiences are just happy chemical accidents? Or, 
as Prince Muishkin wonders, what if some of our peaks are happy 
accidents of disease? What, then, would it mean to “get better”? 
Individuals with bipolar disorder, for example, can have a very dif-
ficult time relinquishing the expansive feelings and creative energies 
that can accompany mania. 
Although these profound questions are the purview of philoso-
phers rather than neuroscientists, few circumstances bring the mind–
brain relationship into question as sharply as becoming victim to a 
neurological or psychiatric disorder. The range of these conditions 
*Dostoevsky F. The Idiot. Translated by Eva Martin. Project Gutenberg EBook, last updated 
May 13, 2017.


===== Page 9 =====
is very wide, from motor disturbances to epilepsy, schizophrenia, 
mood imbalances, cognitive disorders, neurodegeneration, and even 
aging. The more we learn, the more it becomes apparent that these 
diseases exert very broad effects that blur the boundaries between 
their classifications. So-called movement disorders such as Parkinson 
disease, for example, involve cognitive and affective changes; dis-
orders of cognition such as autism or schizophrenia can have very 
physical manifestations. 
Despite these somewhat fuzzy boundaries, each chapter in this sec-
tion will examine the principles underlying each major class of disease 
from the perspective of neuroscience. The emphasis here is on molecu-
lar mechanisms, so far as they are currently understood. It is perhaps 
surprising that so many different disease conditions seem to converge 
on one physiological point: synaptic function. In autism and several 
psychiatric disorders, synaptic development goes awry; in epilepsy, 
abnormal ion channel activity disturbs the balance of synaptic input 
from excitatory and inhibitory neurons. Aging and neurodegenerative 
disorders bring about synaptic loss through gradual alterations in pro-
tein and RNA homeostasis that tax normal cellular functions.
This observation is offered to help give shape to the material you 
are about to encounter, but should not be used to oversimplify. Any-
one tempted by reductionism would do well to engage with the works 
of great artists such as Dostoevsky and Van Gogh, who represent the 
complexities of human experience in all its anguish and glory. 
Part Editor: Huda Y. Zoghbi 
Part IX
Chapter 57	
Diseases of the Peripheral Nerve and Motor Unit
Chapter 58	
Seizures and Epilepsy
Chapter 59	
Disorders of Conscious and Unconscious Mental 
Processes
Chapter 60	
Disorders of Thought and Volition in Schizophrenia
Chapter 61	
Disorders of Mood and Anxiety
Chapter 62	
Disorders Affecting Social Cognition: Autism 
Spectrum Disorder
Chapter 63	
Genetic Mechanisms in Neurodegenerative Diseases 
of the Nervous System
Chapter 64	
The Aging Brain


