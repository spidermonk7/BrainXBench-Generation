===== Page 1 =====
548    Part IV / Perception
Figure 23–3  Orientation selectivity and mechanisms.
A. A neuron in the primary visual cortex responds selectively to 
line segments that fit the orientation of its receptive field. This 
selectivity is the first step in the brain’s analysis of an object’s 
form. (Reproduced, with permission, from Hubel and Wiesel 
1968. Copyright © 1968 The Physiological Society.)
B. The orientation of the receptive field is thought to result from 
the alignment of the circular center-surround receptive fields of 
several presynaptic cells in the lateral geniculate nucleus. In the 
monkey, individual neurons in layer IVCβ of V1 have unoriented 
receptive fields. However, when several neighboring IVCβ cells 
project to a neuron in layer IIIB they create a receptive field with 
a specific orientation for that postsynaptic cell.
from the lateral geniculate nucleus, and there is now 
a body of supportive evidence for the idea. Each 
V1 neuron receives input from several neighboring 
geniculate neurons whose center-surround receptive 
fields are aligned so as to represent a particular axis 
of orientation (Figure 23–3). Two principal types of 
orientation-selective neurons, simple and complex, 
have been identified.
Simple cells have receptive fields divided into ON and 
OFF subregions (Figure 23–4). When a visual stimulus 
such as a bar of light enters the receptive field’s ON sub-
region, the neuron fires; the cell also responds when the 
bar leaves the OFF subregion. Simple cells have a charac-
teristic response to a moving bar; they discharge briskly 
when a bar of light leaves an OFF region and enters an 
ON region. The responses of these cells are therefore 
highly selective for the position of a line or edge in space.
Complex cells are less selective for the position of 
object boundaries. They lack discrete ON and OFF 
subregions (Figure 23–4) and respond similarly to light 
and dark at all locations across their receptive fields. 
They fire continuously as a line or edge stimulus trav-
erses their receptive fields. Hubel and Wiesel proposed 
that the complex cells are a second stage of the elabora-
tion of receptive fields after simple receptive fields and 
are built by overlapping simple receptive fields.
IIIB
IVCβ
Neurons
Receptive ﬁelds
Cortical
layer
A
B
As one considers the range of receptive field prop-
erties that have been described in the early visual cor-
tical areas, it is important to point out phylogenetic 
differences, with different species differing in the loca-
tion in which these properties are first expressed and in 
the kinds of properties that are represented. In the cat, 
the target layer of the visual cortex for lateral genicu-
late neurons has oriented simple cells; it had been pre-
sumed that these cortical cells represent an obligatory 
first stage in the cortical processing of visual informa-
tion, between the center-surround circularly symmet-
ric receptive fields in the lateral geniculate nucleus and 
the receptive fields of complex cells in the superficial 
cortical layers. In primates, however, the geniculate 
target layers, 4Cα and β, have circularly symmetric, 
unoriented receptive fields. The postsynaptic target of 
the layer 4C cells, predominantly the superficial layers 
of the cortex, is populated with complex cells, there-
fore skipping a simple cell stage. In the mouse, orientation 
selectivity is seen in the lateral geniculate nucleus. The 
preceding comparison points out a few characteris-
tics of the evolution of visual processing. One is the 
encephalization of function, where properties such 
as orientation are shifted to later stages of process-
ing over stages of evolution. Another is the develop-
ment of new pathways. It has been suggested that the 


===== Page 2 =====
Chapter 23 / Intermediate-Level Visual Processing and Visual Primitives     549
Figure 23–4  Simple and complex cells in the visual cortex.  
The receptive fields of simple cells are divided into subfields 
with opposite response properties. In an ON subfield (indicated 
by +), the onset of a light triggers a response in the neuron; 
in an OFF subfield (indicated by −), the extinction of a bar of 
light triggers a response. Complex cells have overlapping ON 
and OFF regions and respond continuously as a line or edge 
traverses the receptive field along an axis perpendicular to the 
receptive-field orientation.
Simple cells
+
+
+
+
+
+
+
+
+
+
+
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
+
+
+
+
+
+
+
+
+
+
+
–
–
–
–
–
–
–
–
–
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
–
–
–
–
–
–
–
–
–
Complex cell
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
+
–
magnocellular pathway in the monkey is equivalent to 
the entire geniculostriate pathway in the cat, whereas 
the parvocellular pathway, which mediates higher- 
resolution vision and color vision, is new to the primate.
Moving stimuli are often used to study the recep-
tive fields of visual cortex neurons, not only to simulate 
the conditions under which an object moving in space 
is detected but also to simulate the conditions pro-
duced by eye movements.  As we scan the visual envi-
ronment, the boundaries of stationary objects move 
across the retina. In fact, visual perception requires eye 
movement. Visual cortex neurons do not respond to an 
image that is stabilized on the retina. These neurons 
require transient stimulation (moving or flashing stimuli) 
in order to be activated.
Some visual cortex neurons have receptive fields 
in which an excitatory center is flanked by inhibi-
tory regions. Inhibitory regions along the axis of ori-
entation, a property known as end-inhibition, restrict 
a neuron’s responses to lines of a certain length  
(Figure 23–5). End-inhibited neurons respond well to a 
line that does not extend into the inhibitory flanks but 
lies entirely within the excitatory part of the receptive 
field. Because the inhibitory regions share the orien-
tation preference of the central excitatory region, end-
inhibited cells are selective for line curvature and also 
respond well to corners.
To define the shape of the object as a whole, the 
visual system must integrate the information on local 
orientation and curvature into object contours. The 
way in which the visual system integrates contours 
reflects the geometrical relationships present in the 
natural world (Figure 23–6). As originally pointed out 
by Gestalt psychologists early in the 20th century, con-
tours that are immediately recognizable tend to follow 
the rule of good continuation (curved lines maintain 
a constant radius of curvature and straight lines stay 
straight). In a complex visual scene, such smooth con-
tours tend to “pop out,” whereas more jagged contours 
are difficult to detect.
The responses of a visual cortex neuron can be 
modulated by stimuli that themselves do not activate 
the cell and therefore lie outside the receptive field’s 
core. This contextual modulation endows a neuron with 
selectivity for more complex stimuli than would be 
predicted by placing the components of a stimulus at 
different positions in and around the receptive field. 
The same visual features that facilitate the detection of 
an object in a complex scene (Figure 23–6A) also apply 
to contextual modulation. The properties of the fea-
tures that confer perception of contours, even illusory 
ones, are reflected in the responses of neurons in the 
primary visual cortex, which are sensitive to the global 
characteristics of contours, even those that extend well 
outside their receptive fields.
Contextual influences over large regions of visual 
space are likely to be mediated by connections between 
multiple columns of neurons in the visual cortex that 
have similar orientation selectivity (Figure 23–6B). These 
connections are formed by pyramidal-cell axons that run 
parallel to the cortical surface (see Figure 21–16). The 
extent and orientation dependency of these horizontal 
connections provide the interactions that could mediate 
contour saliency (see Figure 21–14).
Central to the process of contour integration is the 
idea of the association field. The association field refers 


===== Page 3 =====
550    Part IV / Perception
Figure 23–5  End-inhibited receptive 
fields. Some receptive fields have a 
central excitatory region flanked by 
inhibitory regions that have the same 
orientation selectivity. Thus, a short 
line segment or a long curved line will 
activate the neuron (A and C), but a 
long straight line will not (B). A neuron 
with a receptive field that displays only 
one inhibitory region in addition to the 
excitatory region can signal the pres-
ence of corners (D).
Cell 
response
Stimulus
Receptive
ﬁeld
A
B
C
D
to the interactions across visual space required to per-
ceptually link contour elements into global contours. 
It underlies the Gestalt principle of good continuation 
and the perceptual saliency of smooth contours embed-
ded in complex scenes. Physiologically, it underlies the 
facilitation of neuronal responses by contour elements 
extending outside their “classical” receptive fields. 
Anatomically, it is mediated in part by the relation-
ship between long-range horizontal connections and 
cortical functional architecture. Though it has been 
investigated most extensively in primary visual cor-
tex, because of the ubiquity of horizontal connections 
across all areas of cortex, it is likely to be a strategy for 
associating bits of information that are mapped within 
every cortical area. The functional role of the associa-
tion field in cortical areas outside of V1 depends on 
how information is mapped across the cortical sur-
face and the relationship between these maps and the 
plexus of horizontal connections.
Depth Perception Helps Segregate Objects 
From Background
Depth is another key feature in determining the per-
ceived shape of an object. An important cue for the 
perception of depth is the difference between the two 
eyes’ views of the world, which must be computed and 
reconciled by the brain. The integration of binocular 
input begins in the primary visual cortex, the first level 
at which individual neurons receive signals from both 
eyes. The balance of input from the two eyes, a property 
known as ocular dominance, varies among cells in V1.
Binocular neurons in many visual cortical areas 
are also selective for depth, which is computed from 
the relative retinal positions of objects placed at differ-
ent distances from the observer. An object that lies in 
the plane of fixation produces images at corresponding 
positions on the two retinas (Figure 23–7). The images 
of objects that lie in front of or behind the plane of fixa-
tion fall on slightly different locations in the two eyes, 
a property known as binocular disparity. Individual 
neurons can be selective for a narrow range of dispari-
ties and therefore positions in depth. Some are selec-
tive for objects lying on the plane of fixation (tuned 
excitatory or inhibitory cells), whereas others respond 
only when objects lie in front of the plane of fixation 
(near cells) or behind that plane (far cells).
Depth plays an important role in the perception 
of object shape, in surface segmentation, and in estab-
lishing the three-dimensional properties of a scene. 
Objects that are placed near an observer can partially 
occlude those situated farther away. A surface pass-
ing behind an object is perceived as continuous even 
though its two-dimensional image on each retina rep-
resents two surfaces separated by the occluder. When 
the brain encounters a surface interrupted by gaps that 
have appropriate alignment and contrast, and lying in 
the near-depth plane, it fills in the gaps to create a con-
tinuous surface (Figure 23–8).
Although the depth of a single object can be 
established easily, determining the depths of multiple 
objects within a scene is a much more complex problem 
that requires linking the retinal images of all objects 
in the two eyes. The disparity calculation is therefore 
a global one: The calculation in one part of the visual 
image influences the calculation for other parts. When 
the assignment of depth is unambiguous in one part 
of an image, that information is applied to other parts 
of the image where there is insufficient information to 


===== Page 4 =====
Chapter 23 / Intermediate-Level Visual Processing and Visual Primitives     551
Figure 23–6  Contour integration reflects the perceptual 
rules of proximity and good continuation. (Adapted, with 
permission, from Li and Gilbert 2002.)
A. A straight line composed of one or more contour elements 
with the same oblique orientation appears in the center of 
each of the four images here. In some images, the line pops 
out more or less immediately, without searching. Factors that 
contribute to contour saliency include the number of contour 
elements (compare the first and second frames), the spacing of 
the elements (third frame), and the smoothness of the contour 
(bottom frame). When the spacing between elements is too 
large or the orientation difference between them too great, one 
must search the image to find the contour.
B. These perceptual properties are reflected in the horizontal con-
nections between columns of V1 neurons with similar orientation 
selectivity. As long as the visual elements are spaced sufficiently 
close together, excitation can propagate from cell to cell, thus 
facilitating the responses of V1 neurons. Each neuron in the net-
work then augments the responses of neurons on either side, 
and the facilitated responses propagate across the network.
Features affecting contour saliency
Number of line elements
Smoothness of contour
Spacing of collinear line elements
A  Visual ﬁeld
B  Laterally connected V1 neurons


===== Page 5 =====
552    Part IV / Perception
Figure 23–7  Stereopsis and binocular disparity.
A. Depth is computed from the positions at which images 
occur in the two eyes. The image of an object lying in the 
plane of fixation (green) falls on corresponding points on the 
two retinas. Images of objects lying in front of the plane of 
fixation (blue) or behind it (yellow) fall on noncorresponding 
locations on the two retinas, a phenomenon termed binocular 
disparity.
B. Neurons in many visual cortical areas are selective for par-
ticular ranges of disparity. Each plot shows the responses of a 
neuron to binocular stimuli with different disparities (abscissa). 
Some neurons are tuned to a narrow range of disparities and 
thus have particular disparity preferences (tuned excitatory or 
tuned inhibitory neurons), whereas others are tuned broadly for 
objects in front of the fixation plane (near cells) or beyond the 
plane (far cells). (Adapted, with permission, from Poggio 1995. 
Copyright © 1995 Oxford University Press.)
Plane of 
ﬁxation
Fovea
Near
Far
Tuned excitatory cells
A  Binocular disparity of retinal images    
B  Disparity-selective neurons
0
–1.0
1.0
0
–1.0
1.0
0
–1.0
1.0
Tuned inhibitory cell
Horizontal disparity (deg)
Near and far cells 
Near
Far
Zero
determine depth, a phenomenon known as disparity 
capture.
Random-dot stereograms provide a dramatic dem-
onstration of the global scope of disparity analysis. The 
visual information presented to each eye appears to be 
incoherent, but when the stereogram is viewed binocu-
larly, the disparity between the random array of dots in 
the two images allows an embedded shape to become 
visible (Figure 23–8C). The calculation underlying this 
percept is not simple, but requires determining which 
features shown to the left eye correspond to features 
seen by the right eye and propagating local disparity 
information across the image.
Neurons in area V2 display sensitivity to global 
disparity cues. Distant depth cues can be used to link 
contour elements that belong to an object, and to sepa-
rate them from the object background (Figure 23-B).
In addition to binocular disparity, the visual sys-
tem also uses many monocular cues to discriminate 
depth. Depth determination through monocular 


===== Page 6 =====
Figure 23–8  Global analysis of binocular disparity.
A. 1. Depth cues contribute to surface segmentation. If you view 
one of the images of three gray vertical bars crossing a gray 
horizontal rectangle, you see a uniform gray area within the rec-
tangle. 2. However, if you fuse the two rectangles with diverged 
eyes, the three vertical bars fall on the two retinas with near, 
zero, and far disparity. Seen this way, the bar at the left appears 
to hover in front of the rectangle with an illusory vertical edge 
crossing the rectangle, whereas the bar at the right appears to 
lie behind the edges of the horizontal rectangle.
B. A neuron in area V2 responds to illusory edges formed 
by binocular disparity cues. When the cell’s receptive field 
is centered in the gray square, the cell does not respond to 
a vertical bar that has far disparity or the same disparity as 
the square. When the vertical bar has near disparity, the cell 
responds as the illusory vertical edge crosses its receptive 
field. (Reproduced, with permission, from Bakin, Nakayama, 
and Gilbert 2000. Copyright © 2000 Society for Neuroscience.)
C. A random-dot stereogram is seen as a random array of 
colored dots until you diverge or converge your eyes to bring 
the adjacent dark vertical stripes into register, producing a 
three-dimensional image of a shark that emerges from the back-
ground. This effect stems from systematic disparity for selected 
sets of dots. (© Fred Hsu/ Wikimedia Commons/CC-BY-SA-3.0.)
Zero
disparity
“Bar”
is near
“Bar”
is far
Stimulus
Disparity 
information
Percept
V2 cell response
Cell‘s 
receptive ﬁeld
Perceived borders  of stimulus 
cross cell’s receptive ﬁeld
+
A1
B
C
A2


===== Page 7 =====
554    Part IV / Perception
Figure 23–9  Border ownership. Cells in area V2 are  
sensitive to the boundaries of whole objects. Even though 
the local contrast is the same for the two rectangles within a 
cell’s receptive field, the cell responds only when the bound-
ary is part of the full rectangle that lies on the preferred side 
of the receptive field. (Adapted, with permission, from Zhou, 
Friedman, and von der Heydt 2000. Copyright © 2000 Society 
for Neuroscience.)
cues, such as size, perspective, occlusion, brightness, 
and movement, is not difficult. Another cue that 
originates outside the visual system is vergence, the 
angle between the optical axes of the two eyes for 
objects at varying distances. Yet another binocular 
cue, known as DaVinci stereopsis, is the presence of 
features visible to one eye but occluded in the other 
eye’s view.
Neurons in areas V1 and V2 also signal fore-
ground–background relationships. A cell with its 
receptive field in the center of a pattern within a 
larger surface may respond even when the bound-
ary of that surface is distant from the receptive field. 
This response helps differentiate the object from its 
background. In making sense of an image, the brain 
must identify which edge belongs to which object and 
differentiate the edge of each object from the back-
ground. Some cells in area V2 have the property of 
“border ownership,” firing only when a figure but 
not the background is to one side of the edge, even 
when the local edge information is identical in both 
instances (Figure 23–9).
Local Movement Cues Define Object Trajectory 
and Shape
The primary visual cortex determines the direction of 
movement of objects. Directional selectivity in neurons 
likely involves sequential activation of regions on dif-
ferent sides of the receptive field.
If an object moving at an appropriate velocity 
first encounters a region of a neuron’s receptive field 
with long response latencies and then passes into 
regions with progressively shorter latencies, signals 
from throughout the receptive field will arrive at the 
cell simultaneously and the neuron will fire vigor-
ously. If the object moves in the opposite direction, 
signals from the different regions will not summate 
and the cell may never reach the threshold for firing 
(Figure 23–10).
Early in the visual pathways, analysis of the move-
ment of an object is limited by the size of the recep-
tive fields of the sensory neurons. Even in the initial 
cortical areas V1 and V2, the receptive fields of neu-
rons are small and might encompass only a fraction of 
an object. Eventually, however, information about the 
direction and speed of movement of discrete aspects 
of an object must be integrated into a computation of 
the movement of a whole object. This problem is more 
difficult than one might expect.
If one observes a complex shape moving through 
a small aperture, the part of the object’s boundary 
Cell’s 
receptive
ﬁeld
V2 cell response
“Object” is on right (preferred)
side of cell’s receptive ﬁeld
“Object” is on left side 
of cell’s receptive ﬁeld
within the aperture appears to move in a direction 
perpendicular to the boundary’s orientation (Figure 
23–11A). One cannot detect a line’s true direction of 
movement if the line’s ends are not visible. The image 
of a line appears the same if it is moving slowly 
along an axis perpendicular to its orientation or more 
quickly along an oblique axis. This is the quandary 
presented by the receptive field of a V1 neuron. The 
visual system’s solution is to assume that the move-
ment of a contour is perpendicular to its orientation. 
Thus, an object is first presented to the visual system 
in countless small pieces with boundaries of differ-
ent orientations, all of which appear to be moving in 


===== Page 8 =====
Chapter 23 / Intermediate-Level Visual Processing and Visual Primitives     555
Figure 23–10  Directional selectivity of movement. A neu-
ron’s selectivity for direction of movement depends on the 
response latencies of presynaptic neurons relative to the onset 
of a stimulus. The response latencies of presynaptic neurons 
a and b are somewhat longer than those of neurons d and e. 
When a stimulus moves from left to right, neurons a and then 
b are activated first, but because their response latencies are 
longer, their inputs arrive at the target neuron superimposed 
with the inputs from neurons d and e, and the summated 
inputs cause the neuron to fire. In contrast, stimuli moving 
leftward produce signals that arrive in the target neuron at dif-
ferent times and therefore do not reach the cell’s threshold for 
firing. (Abbreviation: EPSP, excitatory postsynaptic potential.) 
(Adapted, with permission, from Priebe and Ferster 2008. 
Copyright © 2008 Elsevier.)
a
b
c
d
e
a
b
c
Target 
cell
d
e
Preferred direction
Nonpreferred direction
Summed 
EPSPs
Threshhold
Spiking 
response 
in target
cell 
e
d
c
b
a
a
b
d
e
b
c
Stimulus onset
different directions and at different velocities (Figure 
23–11A).
Determining the direction of motion of an object 
requires resolving multiple cues. This can be dem-
onstrated readily by placing one grating on top of 
another and moving the two in different directions. 
The resulting checkerboard pattern appears to move 
in an intermediate direction between the trajectories of 
the individual gratings (Figure 23–11B). This percept 
depends on the relative contrast of the gratings and the 
area of grating overlap. With large relative contrasts, 
the gratings appear to slide across each other, moving 
in their individual directions rather than together in a 
common direction.
An important determinant of perceived direction 
is scene segmentation, the separation of moving ele-
ments into foreground and background. In a scene 
with moving objects, segmentation is not based on 
local cues of direction; instead, perception of direction 
depends on scene segmentation. The barber-pole illu-
sion provides another example of the predominance 
of global relationships over the perception of simple 
attributes. The rotating stripes are perceived as mov-
ing vertically along the long axis of the pole (Figure 
23–11C). The perception of motion in the visual field 
uses a complex algorithm that integrates the bottom-
up analysis of local motion signals with top-down 
scene segmentation.
Integration of local motion signals in monkeys 
has been observed in the middle temporal area (area 
MT or V5), an area specializing in motion. The neu-
rons in this area are selective for a particular direction 
of movement of an overall pattern, rather than indi-
vidual components of the pattern. This dependency on 
the overall pattern is also seen in the correspondence 
of their responses with the perceived direction in the 
barber-pole effect.
Context Determines the Perception of  
Visual Stimuli
Brightness and Color Perception Depend on Context
The visual system measures the surface characteristics 
of objects by comparing the light arriving from differ-
ent parts of the visual field. As a result, the percep-
tion of brightness and color is highly dependent on 
context. In fact, perceived brightness and color can be 
quite different from what is expected from the physical 
properties of an object. At the same time, perceptual 
constancies make objects appear similar even when 
the brightness and wavelength distribution of the light 


===== Page 9 =====
556    Part IV / Perception
Figure 23–11  The aperture problem and barber-pole illusion.
A. Although an object moves in one direction, each component 
edge when viewed through a small aperture appears to move 
in a direction perpendicular to its orientation. The visual system 
must integrate such local motion signals into a unified percept 
of a moving object.
B. Gratings are used to test whether a neuron is sensitive to 
local or global motion signals. When the gratings are superim-
posed and moved independently in different directions, one 
does not see the two gratings sliding past each other but rather 
a plaid pattern moving in a single, intermediate direction. Neu-
rons in the middle temporal area of monkeys are responsive to 
such global motion rather than to local motion.
C. Motion perception is influenced by scene segmentation 
cues, as seen in the barber-pole illusion. Even though the pole 
rotates around its axis, one perceives the stripes as moving 
vertically, due to the global vertical rectangle surround of the 
barber pole enclosure.
B 
C 
+
=
Global / object direction
Local / component direction
Illusory direction 
A 
that illuminates them changes from natural to artificial 
light, from sunlight to shadow, or from dawn to mid-
day (Figure 23–12A).
As we move about or as the ambient illumination 
changes, the retinal image of an object—its size, shape, 
and brightness—also changes. Yet under most condi-
tions, we do not perceive the object itself to be chang-
ing. As we move from a brightly lit garden into a dimly 
lit room, the intensity of light reaching the retina may 
vary a thousandfold. Both in the room’s dim illumina-
tion and in the sun’s glare, we nevertheless see a white 
shirt as white and a red tie as red. Likewise, as a friend 
walks toward you, she is seen as coming closer; you do 
not perceive her to be growing larger even though the 
image on your retina does expand. Our ability to per-
ceive an object’s size and color as constant illustrates 
again a fundamental principle of the visual system: It 
does not record images passively, like a camera, but 
instead uses transient and variable stimulation of the 
retina to construct representations of a stable, three-
dimensional world.
Another example of contextual influence is color 
induction, whereby the appearance of a color in one 
region shifts toward that in an adjoining region. Shape 
also plays an important role in the perception of sur-
face brightness. Because the visual system assumes 
that illumination comes from above, gray patches on a 
folded surface appear very different when they lie on 


