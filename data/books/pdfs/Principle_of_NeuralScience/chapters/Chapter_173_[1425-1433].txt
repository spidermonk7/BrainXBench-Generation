===== Page 1 =====
1380    Part VIII / Learning, Memory, and Cognition
Figure 55–4  Dual-stream model of language 
processing.  Temporal and spectral analyses of 
speech signals occur bilaterally in the auditory 
cortex followed by phonological analysis in the 
posterior superior temporal gyri (yellow arrow). 
Processing then diverges into two separate 
pathways: a dorsal stream that maps speech 
sounds to motor programs and a ventral stream 
that maps speech sounds to meaning. The dorsal 
pathway is strongly left hemisphere dominant 
and has segments that extend to the premotor 
cortex (dorsal pathway 1) and to the posterior 
inferior frontal cortex (dorsal pathway 2). The 
ventral pathway occurs bilaterally and extends 
to the anterior temporal lobe and the posterior 
inferior frontal cortex. (Adapted, with permission, 
from Hickok and Poeppel 2007, and Skeide and 
Friederici 2016.)
superior temporal gyrus to the premotor cortex, and 
dorsal pathway 2 connects the posterior superior tem-
poral gyrus to Broca’s area. Pathway 2 is involved in 
higher-order analysis of speech, such as discriminat-
ing subtle differences in meaning based on grammar 
and interpreting language using more complex con-
cepts. The dorsal stream is strongly left hemisphere 
dominant. The arcuate fasciculus and the superior lon-
gitudinal fasciculus are white matter fiber tracts that 
mediate communication along the dorsal stream.
The ventral stream passes below the Sylvian fissure 
and is composed of regions of the superior and mid-
dle temporal lobes as well as regions of the posterior 
inferior frontal lobe. This stream conveys information 
for auditory comprehension, which requires transfor-
mation of the auditory signal to representations in a 
mental lexicon, a “brain-based dictionary” that links 
individual word forms to their semantic meaning. This 
stream comprises the inferior fronto-occipital fascicu-
lus, the uncinate fasciculus, and the extreme fiber cap-
sule system and is largely bilaterally represented.
The cortical brain regions included in the dual-
stream model also interact with spatially distributed 
regions throughout both hemispheres of the brain that 
provide additional information crucial for language 
processing. These regions include the prefrontal cortex 
and cingulate cortices, which exert executive control and 
mediate attentional processes, respectively, as well as 
regions in the medial temporal, frontal, and parietal 
areas involved in memory retrieval.
The Neural Architecture for Language Develops 
Rapidly During Infancy
The study of language development in infancy requires 
a methodology that documents significant changes in 
behavior and links those changes to changes in brain 
function and morphology over time. Neuroimaging 
methods for the infant brain have improved substan-
tially over the past decade, allowing for a detailed 
assessment of the progression of development of 
the specialized regions and structural connections 
required by the language network. For example, devel-
opmental neuroscientists have created models of the 
average infant brain and brain atlases for the infant 
brain at 3 and 6 months of age. These models indicate 
that brain structures essential to language processing 
in adulthood, such as the inferior frontal cortex, pre-
motor cortex, and superior temporal gyrus, support 
speech processing in early infancy. Studies using DTI 
and tractography indicate that the arcuate fasciculus 
and the uncinate fasciculus connect language regions 
by 3 months of age.
The development of the neural substrates for lan-
guage in 1- to 3-day-old infants has been studied in 
depth by Daniela Perani using fMRI and DTI. Perani’s 
fMRI work reveals that listening to speech activates 
the infant superior temporal gyrus bilaterally and 
that in the left hemisphere this activation extends to 
the planum temporale, inferior frontal gyrus, and 
inferior parietal lobe. Perani’s DTI studies of the same 
newborn infants demonstrate weak intrahemispheric 
connections, but strong connections between the hemi-
spheres. Nevertheless, the ventral fiber tract connect-
ing the ventral portion of the inferior frontal gyrus via 
the extreme fiber capsule system to the temporal cortex 
is evident in newborns and in both hemispheres. The 
dorsal pathway connecting the temporal cortex to 
the premotor cortex is also present in the newborns, 
although the dorsal tract that connects the temporal 
cortex to Broca’s area in adults is not detectable in new-
borns. These early connections between sensory areas 
Inferior
frontal gyrus
(Broca’s area)
Anterior middle
and superior
temporal gyri
Premotor
cortex
Ventral pathway
Dorsal pathway 1
Dorsal pathway 2
Posterior middle
temporal gyrus
Auditory
cortex
Posterior superior
temporal gyrus
(Wernicke’s area)


===== Page 2 =====
Chapter 55 / Language    1381
and the premotor cortex are important because they 
may allow the sensory-to-motor mapping essential for 
the development of early imitation of the sounds and 
words of the language.
Jens Brauer and colleagues replicated these find-
ings on the development of ventral and dorsal path-
ways in newborns, revealing the maturational primacy 
of the ventral connection linking temporal areas to the 
inferior frontal gyrus. Brauer also verified that the dor-
sal pathway connects the temporal and premotor cor-
tex at birth and showed that the dorsal pathway to the 
inferior frontal gyrus develops later. Brauer used the 
same protocol with children 7 years of age and adults. 
In 7-year-olds, the dorsal pathway fully connects audi-
tory areas and the inferior frontal gyrus, but in adults, 
it has more extensive and far-reaching connections.
EEG and MEG functional brain imaging studies on 
young infants as early as 2 months of age show that 
the inferior frontal and temporal cortices, implicated 
in both the classical and contemporary models of lan-
guage processing, are activated bilaterally by speech—
syllables, words, and sentences. This finding supports 
the hypothesis that left hemisphere specialization 
increases over time, with syllables showing dominant 
left hemisphere specialization at the end of the first 
year, words by the age of 2, and sentences in middle 
childhood.
EEG and MEG studies of young infants in which 
infants listen passively to native and nonnative sylla-
bles have produced results consistent with the behavio-
ral transitions described earlier in this chapter. Several 
infant laboratories have shown that brain activity in 
response to speech, measured early in development, 
provides sensitive markers that predict language skills 
several years later. These studies hold promise for the 
eventual identification of brain measures in infants that 
indicate risk for developmental disabilities involving 
language, such as autism spectrum disorder, dyslexia, 
and specific language impairment. Early identification 
would allow earlier and more effective interventions 
for these impairments, improving outcomes for these 
children and their families.
Studies using functional MEG brain imaging of 
infants show that at 7 months of age, native and non-
native speech syllables activate not only superior 
temporal regions of the infant brain but also inferior 
frontal regions and the cerebellum, forging an associa-
tion between speech patterns they hear and the motor 
plans they use to babble and imitate. By 12 months of 
age, language experience alters the patterns of activa-
tion in both sensory and motor brain regions.
Auditory activation becomes stronger for native 
sounds, indicating that brain areas have begun to 
become specialized for native language phonology. 
In contrast, motor activation in both Broca’s area and 
the cerebellum is increased in response to nonnative 
sounds, because by 12 months infants have sufficient 
sensorimotor knowledge to imitate native sounds and 
some words and have linked stored auditory patterns 
(words like “cup” and “ball”) to the motor plans neces-
sary to produce them. But they cannot make the senso-
rimotor associations for foreign-language sounds and 
words because the necessary motor plans cannot be 
generated. Therefore, we see longer and more diffuse 
activation as infants struggle to create the motor plans 
for a sound or word they have never experienced. 
The importance of motor learning in language devel-
opment is also shown by longitudinal whole-brain 
voxel-based morphometry studies of 7-month-old 
infants showing that gray matter concentrations in the 
cerebellum correlate with the number of words those 
infants can produce at 1 year of age.
Over the next 5 years, there is likely to be an explo-
sive increase in brain studies focused on development 
of the language network. In a number of laborato-
ries, these brain measures will be linked to behavio-
ral measures, enabling the creation of models that 
delineate how language experience alters the infant 
brain to increase its specialization for the language 
or languages to which the child is exposed. The find-
ing that the classic brain regions known to be part of 
the language network in adults—in particular, the left 
and right temporal cortices and the left inferior frontal 
cortex—are already activated by speech at birth recalls 
Chomsky’s view of innate language capabilities.
The Left Hemisphere Is Dominant for Language
Current views of language processing agree that while 
the neural circuitry necessary for transforming speech 
sounds to meaning may be present in both hemi-
spheres, the left hemisphere is more highly specialized 
for language processing. This left hemisphere domi-
nance develops with maturation and learning.
Evidence from a variety of sources suggests that 
left hemisphere specialization for language develops 
rapidly in infancy. Word learning represents a case in 
point. Deborah Mills and her colleagues used event-
related potentials to track development of the neural 
signals generated in response to words that children 
knew. Her studies showed that both age and lan-
guage proficiency produce changes in the strength 
of the neural responses to known words, as well as 
a change in hemisphere dominance between 13 and 
20 months of age. At the earliest age studied, known 
words activate a broad and bilaterally distributed 


===== Page 3 =====
1382    Part VIII / Learning, Memory, and Cognition
pattern across the brain. As infants approach 20 months 
and vocabulary grows, the activation pattern shifts 
to become left hemisphere dominant in the tem-
poral and parietal regions. In late talkers, this shift 
is delayed to nearly 30 months. In 24-month-old 
children with autism, the degree to which this left 
hemisphere dominance is evident predicts children’s 
linguistic, cognitive, and adaptive abilities at age 6.
Several studies show that immersion in a second 
language in adulthood produces growth in the supe-
rior longitudinal fasciculus, a white matter fiber tract 
that is important for language. Neuroscientist Ping 
Mamiya, collaborating with geneticist Evan Eichler, 
demonstrated, using DTI, that white matter integrity 
of the superior longitudinal fasciculus in the right 
hemisphere increased in Chinese college students in 
proportion to the number of days they spent in an 
English immersion class and decreased after immer-
sion ended. Moreover, analysis of polymorphisms in the 
catechol-O-methyltransferase (COMT) gene showed 
an effect on this relationship—students with two of the 
variants demonstrated these changes, while students 
with the third variant showed no change in white 
matter properties with language experience.
There is great interest in brain studies investigat-
ing the selectivity of the brain mechanisms underlying 
language. Studies in the visual system by neuroscien-
tist Nancy Kanwisher led to the suggestion that cer-
tain visual areas (the fusiform face area) are highly 
selective for particular stimuli, such as faces. Similar 
claims have been advanced for brain areas underlying 
speech analysis. For example, Kanwisher’s group has 
proposed that Broca’s area contains many subregions, 
each highly selective for particular levels of language. 
Additional studies on selectivity, particularly during 
development, will be the focus of future studies.
Helen Neville and Laura-Anne Pettito have shown 
that the left hemisphere is activated not only by audi-
tory stimuli but also by visual stimuli that have linguis-
tic significance. Deaf individuals process sign language 
in left hemisphere speech-processing regions. Such 
studies show that the language network processes lin-
guistic information regardless of modality.
Prosody Engages Both Right and Left Hemispheres 
Depending on the Information Conveyed
Prosodic cues in language can be linguistic, conveying 
semantic meaning as tones do in Mandarin Chinese or 
Thai, as well as paralinguistic, expressing our attitudes 
and emotions. The pitch of the voice carries both kinds 
of information, and the brain’s processing of each kind 
of information differs.
Emotional changes in pitch engage the right 
hemisphere, primarily the right frontal and tempo-
ral regions. Emotional information helps convey a 
speaker’s mood and intentions, and this helps inter-
pret sentence meaning. Patients with right hemisphere 
lesions often produce speech with inappropriate stress, 
timing, and intonation, and their speech sounds emo-
tionally flat; they also frequently fail to interpret the 
emotional cues in others’ speech.
Semantic changes in pitch involve a different 
pattern of brain activity, as demonstrated by neu-
roimaging studies. Jackson Grandour used a novel 
experimental design using Chinese syllables that 
carried either their native Chinese tone or the non-
native Thai tone. fMRI results for both Chinese and 
Thai speakers show higher activation in the left pla-
num temporale for syllables carrying the native tone 
as opposed to nonnative tone (Figure 55–5). The right 
hemisphere did not show this double dissociation, 
supporting the view that language processing occurs 
in the left hemisphere even for auditory signals typi-
cally processed on the right.
Studies of the Aphasias Have Provided  
Insights into Language Processing
According to recent estimates, there are more than 
795,000 strokes per year in the United States. Aphasia 
occurs in 21% to 38% of acute strokes and increases 
the probability of mortality and morbidity. In the 
past decade, the number of individuals with aphasia 
grew by more than 100,000 per year. Broca’s apha-
sia, Wernicke’s aphasia, and conduction aphasia 
compose the three classical models of clinical apha-
sia syndromes. Hickok and Poeppel describe each of 
these subtypes in the context of the dual-stream model. 
Accordingly, Broca’s aphasia and conduction aphasia 
are due to sensorimotor integration problems related 
to damage to the dorsal stream of language process-
ing, whereas Wernicke’s aphasia, word deafness, and 
transcortical sensory aphasia are produced by damage 
to the ventral stream.
Broca’s Aphasia Results From a Large  
Lesion in the Left Frontal Lobe
Broca’s aphasia is a disorder of speech production, 
including impairments in grammatical processing, 
caused by lesions of the dorsal stream. When we 
speak, we rely on auditory patterns stored in the brain. 
Naming a cup when presented with coffee requires a 


===== Page 4 =====
Chapter 55 / Language    1383
Figure 55–5  Brain activation for Chinese and Thai lexical 
tones revealed by functional magnetic resonance imag-
ing. Language stimuli were composed of Chinese syllables 
superimposed with either Thai tones (CT) or Chinese tones (CC). 
Both native Chinese and native Thai speakers demonstrated a 
left hemisphere (LH) dominance when listening to their native 
tones. In the Chinese speakers, activation of the left hemisphere 
was stronger for Chinese tones, whereas in the Thai speak-
ers, activation was stronger for Thai tones. Overlap for the two 
groups occurs in the left planum temporale and the ventral pre-
central gyrus. In the left planum temporale (green crosshairs), 
a double dissociation was found between tonal processing and 
language experience (bar charts). The right hemisphere (RH) did 
not show these effects. (Top left, coronal section; top right, sagit-
tal section; bottom left, axial section.) (Abbreviation: ROI, region 
of interest.) (Adapted, with permission, from Xu et al. 2006. 
Copyright © 2005 Wiley-Liss, Inc.)
patient to connect the stored sensory pattern associated 
with the word “cup” to the motor plans required to hit 
that auditory target. With Broca’s aphasia, the sensory-
motor integration necessary for fluent speech produc-
tion is damaged. Thus, speech is labored and slow, 
articulation is impaired, and the melodic intonation 
of normal speech is lacking (Table 55–2). Yet patients 
sometimes have considerable success at verbal com-
munication because their selection of certain types of 
words, especially nouns, is often correct. By contrast, 
verbs and grammatical words such as prepositions 
and conjunctions are poorly selected or can be missing 
altogether. Another major sign of Broca’s aphasia is a 
defect in the ability to repeat complex sentences.
Because most patients with Broca’s aphasia give 
the impression of understanding conversational 
speech, the condition was initially thought to be a 
deficit of production only. But Broca’s aphasics have 
difficulty comprehending sentences with meanings 
that depend mostly on grammar. Broca’s aphasics can 
understand The apple that the girl ate was green, but have 
trouble understanding The girl that the boy is chasing is 
tall. This is because they can understand the first sen-
tence without recourse to grammatical rules—girls eat 
apples but apples do not eat girls; apples can be green 
but girls cannot. However, they have difficulty with 
the second sentence because both girls and boys can 
be tall, and either can chase the other. To understand 
ROI mean (z-score)
0.0
0.4
0.8
1.2
1.6
Stimulus (tones)
Chinese speaker (CC > CT; p < 0.025)
Thai speaker (CT > CC; p < 0.025)
Overlap (p < 0.025)
Chinese
Thai


===== Page 5 =====
1384    Part VIII / Learning, Memory, and Cognition
Table 55–2  Examples of Spontaneous Speech Production and Repetition for the Primary Types of Aphasia
Type of aphasia
Spontaneous speech
Repetition
 
Stimulus (Western Aphasia Battery picnic picture): What do you see in this 
picture?
Stimulus: “The pastry 
cook was elated.”
Broca
“O, yea. Det’s a boy an’ a girl . . . an’ . . . a . . . car . . . house . . . light po’  
(pole). Dog an’ a . . . boat. ‘N det’s a . . . mm . . . a coffee, an’ reading.  
Det’s a mm . . . a . . . det’s a boy . . . fishin’.” (Elapsed time: 1 min 30 s)
“Elated.”
Wernicke
“Ah, yes, it’s, ah . . . several things. It’s a girl . . . uncurl . . . on a boat.  
A dog . . . ‘S is another dog . . . Uh-oh . . . long’s . . . on a boat. The lady, it’s a 
young lady. An’ a man a They were eatin’. ‘S be place there. This . . . a tree! A 
boat. No, this is a . . . It’s a house. Over in here . . . a cake. An’ it’s, it’s a lot of 
water. Ah, all right. I think I mentioned about that boat. I noticed a boat being 
there. I did mention that before. . . . Several things down, different things 
down . . . a bat . . . a cake . . . you have a . . .” (Elapsed time: 1 min 20 s)
“/I/ . . . no . . . In a fog.”
Conduction
“Kay. I see a guy readin’ a book. See a women /ka . . . he . . . /pourin’ drink  
or something. An’ they’re sittin’ under a tree. An’ there’s a . . . car behind that 
an’ then there’s a house behind th’ car. An’ on the other side, the guy’s flyn’ 
a /fait . . . fait/(kite). See a dog there an’ a guy down on the bank. See a flag 
blowin’ in the wind. Bunch of /hi . . . a . . . /trees in behind. An a sailboat on 
th’ river, river . . . lake. ‘N guess that’s about all. . . . ‘Basket there.” (Elapsed 
time: 1 min 5 s)
“The baker was . . . What 
was that last word?”
(“Let me repeat it: The 
pastry cook was elated.”)
“The baker-er was /
vaskerin/ . . . uh . . .”
Global
(Grunt)
(No response)
the second sentence, it is necessary to analyze its gram-
matical structure, something that Broca’s aphasics 
have difficulty doing.
Broca’s aphasia results from damage to Broca’s 
area (the left inferior frontal gyrus); the surrounding 
frontal fields; the underlying white matter, insula, and 
basal ganglia; and a small portion of the anterior supe-
rior temporal gyrus (Figure 55–6). A small sector of 
the insula, an island of cortex buried deep inside the 
cerebral hemisphere, can also be included among the 
neural correlates of Broca’s aphasia. Broca’s aphasics 
typically have no difficulty perceiving speech sounds 
or recognizing their own errors and no trouble in 
coming up with words. When damage is restricted to 
Broca’s area alone or to its subjacent white matter, the 
result is the condition of Broca’s area aphasia, a milder 
version of true Broca’s aphasia, from which many 
patients are able to recover.
Wernicke’s Aphasia Results From Damage to Left 
Posterior Temporal Lobe Structures
Wernicke’s aphasics have difficulty comprehending 
the sentences uttered by others, and damage occurs 
in areas of the brain that subserve grammar, attention, 
and word meaning. Wernicke’s aphasia can be caused 
by damage to different levels of the ventral stream, where 
auditory information is linked to word knowledge. It is 
usually caused by damage to the posterior section of 
the left auditory association cortex, although in severe 
cases, the middle temporal gyrus and white matter are 
involved (Figure 55–7).
Patients with Wernicke’s aphasia can produce 
speech at a normal rate that sounds effortless, melodic, 
and quite unlike that of patients with Broca’s apha-
sia. But speech can be unintelligible as well because 
Wernicke’s aphasics often shift the order of individual 
sounds and sound clusters. These errors are called  
phonemic paraphasias (a paraphasia is substitution of an 
erroneous phoneme for the correct one). Even when 
individual sounds are normally produced, Wernicke’s 
aphasics have great difficulty selecting words that 
accurately represent their intended meaning (known 
as a verbal or semantic paraphasia). For example, a 
patient might say headman when they mean president.
Conduction Aphasia Results From Damage to a 
Sector of Posterior Language Areas
Conduction aphasia, like Broca’s aphasia, is thought 
to involve the dorsal stream. Speech production and 
auditory comprehension are less compromised than 


===== Page 6 =====
Chapter 55 / Language    1385
Figure 55–6  Sites of lesions in Broca’s aphasia. (Images 
used with permission of Hanna and Antonio Damasio.)
A. Top: A three-dimensional magnetic resonance imaging (MRI) 
reconstruction of a lesion (infarction) in the left frontal operculum 
(dark gray) in a patient with Broca’s aphasia. Bottom: A coronal 
MRI section of the same brain through the damaged area.
B. Top: A three-dimensional MRI overlap of lesions in 13 
patients with Broca’s aphasia (red indicates that lesions in five 
or more patients share the same pixels). Bottom: A coronal 
MRI section of the same composite brain image through the 
damaged area.
Figure 55–7  Sites of lesions in Wernicke’s aphasia. (Images 
reproduced, with permission, from Hanna and Antonio Damasio.)
A. Top: Three-dimensional magnetic resonance imaging (MRI)  
reconstruction of a lesion (an infarction) in the left posterior  
and superior temporal cortex (dark gray) in a patient with  
Wernicke’s aphasia. Bottom: Coronal MRI section of the same 
brain through the damaged area.
B. Top: Three-dimensional MRI overlap of lesions in 13 patients 
with Wernicke’s aphasia obtained with the MAP-3 technique 
(red indicates that five or more lesions share the same pixels). 
Bottom: Coronal MRI section of the same composite brain 
image through the damaged area.
A
B
A
B


===== Page 7 =====
1386    Part VIII / Learning, Memory, and Cognition
in the two other major aphasias, but patients cannot 
repeat sentences verbatim, cannot assemble phonemes 
effectively (and thus produce many phonemic para-
phasias), and cannot easily name pictures and objects 
(Table 55–2).
Conduction aphasia is caused by damage to the 
left superior temporal gyrus and the inferior pari-
etal lobe. The damage can extend to the left primary 
auditory cortex, the insula, and the underlying 
white matter. Large lesions in the Sylvian parietal 
temporal area, situated in the middle of the network 
of auditory and motor regions, are consistent with 
the idea that the damage occurs in the dorsal stream. 
Damage to left hemisphere auditory regions often 
produces speech production deficits, supporting the 
idea that sensory systems participate in speech pro-
duction. Such lesions interrupt the interfaces link-
ing auditory representations of words and the motor 
actions used to produce them. The damage com-
promises white matter (dorsal stream) and affects 
feedforward and feedback projections that intercon-
nect areas of temporal, parietal, insular, and frontal 
cortex.
Global Aphasia Results From Widespread Damage 
to Several Language Centers
Patients with global aphasia are almost completely 
unable to comprehend language or formulate and 
repeat sentences, thus combining features of Broca’s,  
Wernicke’s, and conduction aphasias. Speech is 
reduced to a few words at best. The same word 
might be used repeatedly, appropriately or not, in a 
vain attempt to communicate an idea. Nondeliberate 
(“automatic”) speech may be preserved, however. This 
includes stock expletives (which are used appropri-
ately and with normal phonemic, phonetic, and inflec-
tional structures), routines such as counting or reciting 
the days of the week, and the ability to sing previously 
learned melodies and their lyrics. Auditory compre-
hension is limited to a small number of words and idi-
omatic expressions.
Classic global aphasia involves damage to the 
inferior frontal and parietal cortices (as seen in Broca’s 
aphasia), the auditory cortex and the insula (as seen in 
conduction aphasia), and the posterior superior tem-
poral cortex (as seen in Wernicke’s aphasia). Subcorti-
cal regions, such as the basal ganglia, are often affected 
as well. Such widespread damage is typically caused 
by a stroke in the region supplied by the middle cer-
ebral artery. Weakness in the right side of the face and 
paralysis of the right limbs accompany classic global 
aphasia.
Transcortical Aphasias Result From Damage to 
Areas Near Broca’s and Wernicke’s Areas
Aphasias can be caused by damage not only to speech 
centers of the cortex but also to pathways that connect 
those components to the rest of the brain. Transcortical 
aphasia can be either motor or sensory. Patients with 
transcortical motor aphasia speak nonfluently, but they 
can repeat sentences, even very long sentences. Trans-
cortical motor aphasia has been linked to damage to 
the left dorsolateral frontal area, a patch of association 
cortex anterior and superior to Broca’s area, although 
there can be substantial damage to Broca’s area itself. 
The left dorsolateral frontal cortex is involved in the 
allocation of attention and the maintenance of higher 
executive abilities, including the selection of words.
Transcortical motor aphasia can also be caused by 
damage to the left supplementary motor area, located 
high in the frontal lobe, directly in front of the primary 
motor cortex and buried mesially between the hemi-
spheres. Electrical stimulation of the area in nonaphasic 
surgery patients causes the patients to make invol-
untary vocalizations or to be unable to speak, and 
functional neuroimaging studies have shown it to be 
activated during speech production. Thus, the supple-
mentary motor area appears to contribute to the initia-
tion of speech, whereas the dorsolateral frontal regions 
contribute to ongoing control of speech, particularly 
when the task is difficult.
Transcortical sensory aphasics have fluent speech, 
impaired comprehension, and great trouble nam-
ing things. These patients have deficits in semantic 
retrieval, without significant disruption of syntactic 
and phonological abilities.
Transcortical motor and sensory aphasias are 
caused by damage that spares the arcuate fascicu-
lus and the dorsal stream. Transcortical aphasias are 
thus the complement of conduction aphasia, behavio-
rally and anatomically. Transcortical sensory aphasia 
appears to be caused by damage to the ventral stream, 
affecting parts of the junction of the temporal, parietal, 
and occipital lobes, which connect the perisylvian lan-
guage areas with the parts of the brain responsible for 
word meaning.
Less Common Aphasias Implicate Additional  
Brain Areas Important for Language
Several other language-related regions in the cerebral 
cortex and subcortical structures, for example, the 
anterior temporal and inferotemporal cortex, have 
only recently become associated with language. Dam-
age to the left temporal cortex causes severe and pure 


===== Page 8 =====
Chapter 55 / Language    1387
Figure 55–8  Regions of the brain other than 
Broca’s and Wernicke’s areas involved in lan-
guage processing. Functional magnetic reso-
nance imaging was used to study patients with 
selected brain lesions. (Images reproduced, with 
permission, from Hanna and Antonio Damasio.)
A. The region of maximal overlap of lesions 
associated with impaired naming of unique 
images, such as the face of a person, is the left 
anterior temporal pole.
B. The sites of maximal overlap of lesions asso-
ciated with impaired naming of nonunique ani-
mals are the left anterolateral and posterolateral 
temporal regions as well as Broca’s region.
C. The sites of maximal overlap of lesions asso-
ciated with deficits in naming of tools are the 
left sensorimotor cortex and left posterolateral 
temporal cortex.
naming defects—impairments of word retrieval with-
out any accompanying grammatical, phonemic, or 
phonetic difficulty.
When the damage is confined to the left temporal 
pole, the patient has difficulty recalling the names of 
unique places and persons but not the names of com-
mon things. When the lesions involve the mid-temporal 
sector, the patient has difficulty recalling both unique 
and common names. Finally, damage to the left poste-
rior inferotemporal sector causes a deficit in recalling 
words for particular types of items—tools and 
utensils—but not words for natural or unique things. 
Recall of words for actions or spatial relationships is 
not compromised (Figure 55–8).
The left temporal cortex contains neural systems 
that hold the key to retrieving words denoting vari-
ous categories of things (“tools,” “eating utensils”), 
but not words denoting actions (“walking,” “riding a 
bicycle”). These findings were obtained not only from 
studies of patients with brain lesions resulting from 
A  Defective naming of unique images
B  Defective naming of animals
C  Defective naming of tools
Left anterior
temporal pole
Left posterolateral 
temporal region
Broca’s 
area
Left anterolateral 
and posterolateral 
temporal regions
Inferior 
sensorimotor 
cortex


===== Page 9 =====
1388    Part VIII / Learning, Memory, and Cognition
stroke, head injury, herpes encephalitis, and degenera-
tive processes such as Alzheimer disease, but also from 
functional imaging studies of typical individuals and 
from electrical stimulation of these same areas of tem-
poral cortex during surgery.
Areas of frontal cortex in the mesial surface of the 
left hemisphere, which include the supplementary 
motor area and the anterior cingulate region, play an 
important role in the initiation and continuation of 
speech. Damage in these areas impairs the initiation of 
movement (akinesia) and causes mutism, a complete 
absence of speech. In aphasic patients, the complete 
absence of speech is a rarity and is only seen during 
the very early stages of the condition. Patients with 
akinesia and mutism fail to communicate by words, 
gestures, or facial expression because the drive to com-
municate is impaired, not because the neural machin-
ery of expression is damaged as in aphasia.
Damage to the left subcortical gray nuclei impairs 
grammatical processing in both speech and compre-
hension. The basal ganglia are closely interconnected 
with the frontal and parietal cortex and may have a 
role in assembling morphemes into words and words 
into sentences, just as they serve to assemble the com-
ponents of a complex movement into a smooth action.
Highlights
1.	 Language exists at many levels, each of which has 
to be mastered during childhood—the elemental 
phonetic units (vowels and consonants) used to 
change the meaning of a word, the words them-
selves, word endings (morphemes) that change 
tense and pluralization, and the grammatical rules 
that allow words to be strung together to create 
sentences with meaning. By the age of 3, young 
children, regardless of the language(s) they are 
learning, have mastered all levels and can carry on 
a conversation with an adult. No artificially intel-
ligent machine can yet duplicate this feat.
2.	 The learning strategies used by children to mas-
ter language under 1 year of age are surprising.  
Language learning proceeds as infants (1) exploit 
the statistical properties of speech (distribu-
tional frequency patterns of sounds to detect rel-
evant phonetic units and transitional probabilities 
between adjacent syllables to detect likely words), 
and (2) exploit the social context in which lan-
guage occurs by following the eye movements of 
adults as they refer to objects and actions to learn 
word–object and word–action correspondences. 
At early ages, natural language learning requires a 
social context and social interaction. Infants’ strat-
egies are not well described by Skinnerian operant 
conditioning or by Chomsky’s innate representa-
tion and selection based on experience. Instead, 
powerful implicit learning mechanisms that oper-
ate in social contexts vault infants forward from 
the very earliest months of life.
3.	 Infants’ speech production and speech percep-
tion skills are “universal” at birth. In speech per-
ception, infants discriminate all sounds used to 
distinguish words across all languages until the 
age of 6 months. By 12 months, discrimination 
for native-language sounds has dramatically 
increased, whereas discrimination of foreign-
language sounds decreases. Production is ini-
tially universal as well and becomes language 
specific by the end of the first year. By the age of 
3, infants know 1,000 words. Mastery of gram-
matical structure in complex sentences continues 
until the age of 10. Future work will advance the 
field by linking the detailed behavioral mile-
stones that now exist to functional and structural 
brain measures to show how the brain’s network 
for language is shaped as a function of language 
experience.
4.	 A new “dual-stream” model of language has 
emerged based on advances in functional neural 
imaging and structural brain imaging over the 
past decade. The new model bears similarities to 
the dual-stream model for the visual system. The 
dual-stream model for language goes beyond the 
classic Wernicke-Geschwind model by showing 
that numerous brain regions and the neural path-
ways that connect them support sound-to-meaning 
(ventral) and sound-to-articulation (dorsal) path-
ways. Refinement in the model will continue as 
additional studies show relationships between 
behavioral and brain measures. Future studies will 
integrate structural and functional brain measures, 
genetic measures, and behavioral assessments of 
language processing and of learning, including 
second language learning in adulthood.
5.	 Studies on the infant brain reveal a remarkably 
well-developed set of brain structures and path-
ways by 3 to 6 months of age. Structural DTI 
reveals a fully formed ventral pathway at birth 
and a dorsal pathway that links auditory areas to 
premotor, but not Broca’s, area at birth. EEG and 
MEG brain imaging studies mirror the transition 
in phonetic perception between 6 and 12 months 
of age, a “critical period” for sound learning. MEG 


