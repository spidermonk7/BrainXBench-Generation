import os
from utils import *
from omegaconf import OmegaConf
from argparse import ArgumentParser
from tqdm import tqdm
# ËØªÂèñÈÖçÁΩÆ
cfg = OmegaConf.load("configs/forward_config.yaml")


def generate_forward(task, 
                    prompt_path, 
                    source_path, 
                    save_path, 
                    model_name = "gpt-4o", 
                    version = "BrainX-v1", 
                    ):
    """
    Function for generating the forward bench, including two steps: Split and Flip.
    
    (1) Split: Segment the abstract into Background, Method, and Results.
    (2) Flip: Modify Method and Results part, offer incorrect choice for model evaluation. 
    (3) Save the results to a new csv file.

    """

    paper_infos = load_csv(source_path)
    save_path = save_path + task
    check_path(save_path)

    if os.path.exists(save_path + f"/{task}_data.csv"):
        last_id = len(load_csv(save_path + f"/{task}_data.csv"))
    else:
        last_id = -1

    for id, paper_info in tqdm(enumerate(paper_infos), desc=f"ü§ñ: Processing abstracts", total = len(paper_infos)):
        if id < last_id: continue
        if task == "split":
            params = {
                "abstract": paper_info["Abstract"],
            }
        elif task == "flip":
            assert "Background" in paper_info.keys() and "Method" in paper_info.keys() and "Result" in paper_info.keys(), "Background, Method, and Results are required in the csv file."
            params = {
                "background": paper_info["Background"],
                "method": paper_info["Method"],
                "results": paper_info["Result"],
            }
        elif task == "validate":
            params = {
            "initial_conclusion": paper_info["Result"],
            "Opposite_Outcome": paper_info["Opposite_Outcome"],
            "Factor_Misattribution": paper_info["Factor_Misattribution"],
            "Incorrect_Causal_Relationship": paper_info["Incorrect_Causal_Relationship"],
            }
        prompt = load_prompt(prompt_path, params)
        try:
            output = LLM_response(prompt=prompt, model_name=model_name)
            response = eval(output.strip())
        except:
            with open(f"{save_path}/error.log", "a") as f:
                f.write(f"Error occurs when processing abstract {id}, program exits.\n")
                f.write(f"Response: {output}")
            raise ValueError(f"Error occurs when processing abstract {id} for bench: {version}.")
        
        for key in response.keys():
            paper_info[key] = response[key]
       
        bench_data = [paper_info]
        save_to_csv(bench_data, save_path, f"{task}_data")


def raw_abs_ana(path, save = True):
    # Âä†ËΩΩÊï∞ÊçÆ
    """[Function Card]
    Function for analyse the raw abstract data, here we will:
    (1) Check the sources for papers we got. 
    (2) Check their publish date. 
    (3) Filter out the top-10(Selected) Journals with good fame and high quality. 
    """
    abs_data = load_csv(path)
    filtered_data = [item for item in abs_data if item["Source"] in cfg.JOURNALS and item["Published Date"] in cfg.DATES_CONSIDERED and item["Abstract"] != "N/A"]
    
    save_path = path.replace("/combined_abstracts.csv", '').replace("raw_abs", "valid_stage_01")
    check_path(save_path)
    file_name = "selected_data"
    if save:
        if os.path.exists(save_path + f"/{file_name}.csv"):
            if input(f"‚ùì: There already exist a file named: {file_name}.csv at location {save_path}, do you want to overwrite it? (y/n): ") == "y":
                os.remove(save_path + f"/{file_name}.csv")
                save_to_csv(filtered_data, save_path, file_name)
        else:
            save_to_csv(filtered_data, save_path, file_name)
    print(f"üìö: Found {len(filtered_data)} papers that should be taken into consideration.")

    return filtered_data


def plot_stacked_distribution(data, key, sub_key, plot=False):
    result_dic = defaultdict(lambda: defaultdict(int))
    # ËÆ°ÁÆóÊØè‰∏™ source ÂÜÖÈÉ®‰∏çÂêå pubdate ÁöÑÊï∞Èáè
    for item in data:
        result_dic[item[key]][item[sub_key]] += 1

    if plot:
        plt.style.use('ggplot')
        # Ëé∑Âèñ‰∏çÂêåÁöÑ source ÂíåÂÆÉ‰ª¨ÂØπÂ∫îÁöÑ pubdate
        sources = list(result_dic.keys())
        label_sources = sources
        if key == "Source":
            label_sources = [cfg.LABEL_MATCHING_DIC[source] for source in sources]
        
        pubdates = sorted(set(date for subdict in result_dic.values() for date in subdict.keys()))
        # È¢úËâ≤ÂàÜÈÖç
        color_range = np.linspace(0.3, 0.8, len(pubdates))  
        colors = [plt.cm.Greys(c) for c in color_range]

        # ÁîªÂ∏ÉÂ§ßÂ∞è
        plt.figure(figsize=(10, 8))
        
        # ÁªòÂà∂Â†ÜÂè†Êü±Áä∂ÂõæÔºàÊ∞¥Âπ≥Ôºâ
        bottom = np.zeros(len(sources))  # Áî®‰∫éÁ¥ØËÆ°ÊØè‰∏™ source ÁöÑ bar Â∑¶‰æßËµ∑ÁÇπ
        for i, pubdate in enumerate(pubdates):
            values = [result_dic[source].get(pubdate, 0) for source in sources]
            plt.barh(label_sources, values, left=bottom, color=colors[i], label=pubdate)
            bottom += np.array(values)

        # Ê∑ªÂä†Ê†áÁ≠æ
        for i, source in enumerate(sources):
            total = sum(result_dic[source].values())
            plt.text(total + 1, i, total, va='center', ha='left')

        plt.yticks(rotation=0)
        plt.xlabel("Count")
        plt.ylabel(key.capitalize())
        plt.legend(title=sub_key, loc="upper right")
        plt.tight_layout()
        plt.show()
        plt.close()

    return result_dic


def check_abs(abs_data):
    """
    Function for checking the validity of raw abstract data. 
    (1) Check if there is any nan in the data, if so, ignore that item. 
    (2) Save the valid papers to a new csv file.

    """
    # TODO: 
    # (1) The saving logic should be redirected to a new path.
    valids = []
    for _, item in enumerate(abs_data):
        for id, key in enumerate(item.keys()):
            if pd.isna(item[key]):
                # print(f"‚ùå: {key} is a nan in the {_}th paper.")
                with open(f"workspaces/{cfg.bench_name}/data/raw_abs/error.log", "a") as f:
                    f.write(f"{key} is a nan in the {_}th paper, DOI: {item['DOI']}.\n")
                break
            if id == len(item.keys()) - 1 and item not in valids:
                valids.append(item)
    return valids


def check_split_result(path, save = True):
    """
    Function for checking the split result of the raw data. 
    (1) Check if there is any nan in the data, if so, ignore that item. 
    (2) Save the valid papers to a new csv file.
    """
    data = load_csv(path)
    filter_out_nan = check_abs(data)
    save_path = f"workspaces/{cfg.bench_name}/data/forward/split"
    check_path(save_path)
    valids = []
    for id, item in enumerate(filter_out_nan):
        if item['Intact_or_not'] == 1 and item['Neuroscience related'] == 1 and item['Research_or_not'] == 1:
            valids.append(item)
        else:
            with open(f"{save_path}/error.log", "a") as f:
                f.write(f"‚ùå: The {id}th paper is not valid for the split data, DOI: {item['DOI']}\n")
    if save:
        if os.path.exists(f"workspaces/{cfg.bench_name}/data/forward/split/split_valids.csv"):
            if input("The file already exists, do you want to overwrite it? (y/n): ") == "y":
                os.remove(f"workspaces/{cfg.bench_name}/data/forward/split/split_valids.csv")
                save_to_csv(valids, save_path, name = "split_valids")
        else:
            save_to_csv(valids, save_path, name = "split_valids")

    return valids







if __name__ == "__main__":
    args = ArgumentParser()
    args.add_argument("-S", "--stage", type=str, default="split")

    args = args.parse_args()


    if args.stage == "S_V_S":
        filtered_data = raw_abs_ana(path = f"workspaces/{cfg.bench_name}/data/raw_abs/combined_abstracts.csv", save=True)
        distribution_info = plot_stacked_distribution(filtered_data, "Source", "Published Date", plot=False)
    
        generate_forward('split', 
                        prompt_path='prompts/forwards/split.md',
                        source_path=f'workspaces/{cfg.bench_name}/data/valid_stage_01/selected_data.csv',
                        save_path=f'workspaces/{cfg.bench_name}/data/forward/',
                        version=cfg.bench_name,
                        )
        
        path = f"workspaces/{cfg.bench_name}/data/forward/split/split_data.csv"
        valids = check_split_result(path=path, save=True)
        print(f"‚úÖ: Split data is validated, find in all {len(valids)} valid papers.")

    elif args.stage == "flip":
        generate_forward('flip', 
                    prompt_path='prompts/forwards/flip.md',
                    source_path=f'workspaces/{cfg.bench_name}/data/forward/split/split_valids.csv',
                    save_path=f'workspaces/{cfg.bench_name}/data/forward/',
                    version=cfg.bench_name,
                    )
        
    elif args.stage == "validate":
        generate_forward(
        task="validate", 
        prompt_path="prompts/forwards/validation.md", 
        source_path=f"workspaces/{cfg.bench_name}/data/forward/flip/flip_data.csv",
        save_path=f"workspaces/{cfg.bench_name}/data/forward/", 
    )

